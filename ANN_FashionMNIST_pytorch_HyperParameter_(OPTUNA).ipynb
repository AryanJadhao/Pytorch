{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Am_Ck9Ynnq0N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxwH04ITLBVd",
        "outputId": "3355d82b-9b08-4e44-af0b-23149f82c3e4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lay18cJoClP",
        "outputId": "c369f26b-b384-466f-8723-90ac23d78079"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79430bb81490>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Fashion MNIST dataset/fashion-mnist_train.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "3zHTvWVroKZr",
        "outputId": "17447e50-b919-4df9-8ac7-0b3a14421c28"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0          2       0       0       0       0       0       0       0       0   \n",
              "1          9       0       0       0       0       0       0       0       0   \n",
              "2          6       0       0       0       0       0       0       0       5   \n",
              "3          0       0       0       0       1       2       0       0       0   \n",
              "4          3       0       0       0       0       0       0       0       0   \n",
              "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "59995      9       0       0       0       0       0       0       0       0   \n",
              "59996      1       0       0       0       0       0       0       0       0   \n",
              "59997      8       0       0       0       0       0       0       0       0   \n",
              "59998      8       0       0       0       0       0       0       0       0   \n",
              "59999      7       0       0       0       0       0       0       0       0   \n",
              "\n",
              "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              "0           0  ...         0         0         0         0         0   \n",
              "1           0  ...         0         0         0         0         0   \n",
              "2           0  ...         0         0         0        30        43   \n",
              "3           0  ...         3         0         0         0         0   \n",
              "4           0  ...         0         0         0         0         0   \n",
              "...       ...  ...       ...       ...       ...       ...       ...   \n",
              "59995       0  ...         0         0         0         0         0   \n",
              "59996       0  ...        73         0         0         0         0   \n",
              "59997       0  ...       160       162       163       135        94   \n",
              "59998       0  ...         0         0         0         0         0   \n",
              "59999       0  ...         0         0         0         0         0   \n",
              "\n",
              "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
              "0             0         0         0         0         0  \n",
              "1             0         0         0         0         0  \n",
              "2             0         0         0         0         0  \n",
              "3             1         0         0         0         0  \n",
              "4             0         0         0         0         0  \n",
              "...         ...       ...       ...       ...       ...  \n",
              "59995         0         0         0         0         0  \n",
              "59996         0         0         0         0         0  \n",
              "59997         0         0         0         0         0  \n",
              "59998         0         0         0         0         0  \n",
              "59999         0         0         0         0         0  \n",
              "\n",
              "[60000 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c12270f2-8402-4e62-b664-3740cf1e8609\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>160</td>\n",
              "      <td>162</td>\n",
              "      <td>163</td>\n",
              "      <td>135</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c12270f2-8402-4e62-b664-3740cf1e8609')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c12270f2-8402-4e62-b664-3740cf1e8609 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c12270f2-8402-4e62-b664-3740cf1e8609');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e018ab03-d9a1-4468-8f59-2e2812b91782\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e018ab03-d9a1-4468-8f59-2e2812b91782')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e018ab03-d9a1-4468-8f59-2e2812b91782 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ac906c33-5cba-46b5-8479-f6d443ff5ba4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ac906c33-5cba-46b5-8479-f6d443ff5ba4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:, 1:].values\n",
        "y = df.iloc[:,0].values\n"
      ],
      "metadata": {
        "id": "-duZn44Oocxa"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "csOVkeT1o847"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the features\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "metadata": {
        "id": "Ws-cvdwVpJlK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsQv3P6dpYlr",
        "outputId": "ed1f3003-2763-4842-e1e0-09c618b971ef"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.00392157, 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create customDataset class\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, features, labels):\n",
        "    self.features = torch.tensor(features, dtype=torch.float32)\n",
        "    self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.features[index], self.labels[index]"
      ],
      "metadata": {
        "id": "s4RLD9pkpl_q"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create train_dataset object\n",
        "train_dataset = CustomDataset(x_train, y_train)"
      ],
      "metadata": {
        "id": "Ch1XrDh7qjcg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLVo5G36q2T1",
        "outputId": "0762e68c-bafd-4af8-a240-1f5fb7e71286"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2275,\n",
              "         0.5333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0078, 0.0275, 0.0078, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.2157, 0.3137, 0.4235,\n",
              "         0.5922, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0078, 0.0196, 0.0000,\n",
              "         0.0078, 0.0078, 0.0471, 0.2863, 0.4039, 0.5137, 0.5608, 0.5608, 0.6902,\n",
              "         0.6314, 0.3333, 0.3843, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000,\n",
              "         0.0588, 0.4235, 0.5216, 0.5608, 0.7412, 0.7686, 0.7686, 0.7020, 0.4431,\n",
              "         0.3059, 0.1255, 0.0000, 0.2078, 0.4431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196,\n",
              "         0.0000, 0.0471, 0.1843, 0.1569, 0.1843, 0.0588, 0.0000, 0.0000, 0.0784,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.7608, 0.2157, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0078, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0078, 0.7882, 0.6314, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0078, 0.0078, 0.0196, 0.0000,\n",
              "         0.0000, 0.0000, 0.0078, 0.0078, 0.0000, 0.0000, 0.1059, 0.8000, 0.6510,\n",
              "         0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0078, 0.0078, 0.0000, 0.0196, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3922, 0.8196,\n",
              "         0.5804, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0078, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0196, 0.0078, 0.0000, 0.0078, 0.0000, 0.0000, 0.6706,\n",
              "         0.8902, 0.1961, 0.1647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980,\n",
              "         0.9765, 0.5137, 0.1765, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667,\n",
              "         0.2667, 0.4157, 0.2353, 0.3451, 0.1255, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.1843,\n",
              "         0.2745, 0.7490, 0.4431, 0.0863, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.0980, 0.2941,\n",
              "         0.6902, 0.8314, 0.4235, 0.4824, 0.1373, 0.0863, 0.0275, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0980, 0.2863, 0.5804,\n",
              "         0.8196, 0.1647, 0.0000, 0.0000, 0.1255, 0.4627, 0.0196, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.3255, 0.6118,\n",
              "         0.5922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.6235, 0.1961, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0196, 0.3451, 0.6824,\n",
              "         0.4235, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.8196, 0.2863,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1059, 0.0667, 0.4627,\n",
              "         0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.6627,\n",
              "         0.4627, 0.0000, 0.0000, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.6627,\n",
              "         0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.2078, 0.0392,\n",
              "         0.3059, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.8000,\n",
              "         0.5333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n",
              "         0.6902, 0.4157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0275, 0.0000,\n",
              "         0.0275, 0.0196, 0.6431, 0.0078, 0.0000, 0.0000, 0.0000, 0.2941, 0.5725,\n",
              "         0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000,\n",
              "         0.0000, 0.7294, 0.4824, 0.0000, 0.1176, 0.2353, 0.0980, 0.1059, 0.2667,\n",
              "         0.3255, 0.1843, 0.2078, 0.3725, 0.1765, 0.0000, 0.0784, 0.4627, 0.6627,\n",
              "         0.6235, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.6627, 0.3333, 0.0000, 0.1059, 0.4627, 0.5216, 0.4745,\n",
              "         0.3922, 0.5412, 0.2941, 0.3137, 0.2863, 0.4745, 0.5412, 0.5412, 0.6824,\n",
              "         0.6314, 0.0078, 0.0000, 0.0196, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0078, 0.0000, 0.6235, 0.5608, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0196, 0.1176, 0.2078, 0.1961, 0.3137, 0.2549, 0.4157, 0.5137, 0.1961,\n",
              "         0.2275, 0.0000, 0.0000, 0.0000, 0.0078, 0.0275, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.5529, 0.5804, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]),\n",
              " tensor(5))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create test_dataset object\n",
        "test_dataset = CustomDataset(x_test, y_test)"
      ],
      "metadata": {
        "id": "EWUqmcsTqtht"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dlh1w-zeqy8A",
        "outputId": "5540089c-cda0-4b39-fa55-41d9598a55c5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2275,\n",
              "         0.5333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0078, 0.0275, 0.0078, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.2157, 0.3137, 0.4235,\n",
              "         0.5922, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0078, 0.0196, 0.0000,\n",
              "         0.0078, 0.0078, 0.0471, 0.2863, 0.4039, 0.5137, 0.5608, 0.5608, 0.6902,\n",
              "         0.6314, 0.3333, 0.3843, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000,\n",
              "         0.0588, 0.4235, 0.5216, 0.5608, 0.7412, 0.7686, 0.7686, 0.7020, 0.4431,\n",
              "         0.3059, 0.1255, 0.0000, 0.2078, 0.4431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196,\n",
              "         0.0000, 0.0471, 0.1843, 0.1569, 0.1843, 0.0588, 0.0000, 0.0000, 0.0784,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.7608, 0.2157, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0078, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0078, 0.7882, 0.6314, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0078, 0.0078, 0.0196, 0.0000,\n",
              "         0.0000, 0.0000, 0.0078, 0.0078, 0.0000, 0.0000, 0.1059, 0.8000, 0.6510,\n",
              "         0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0078, 0.0078, 0.0000, 0.0196, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3922, 0.8196,\n",
              "         0.5804, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0078, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0196, 0.0078, 0.0000, 0.0078, 0.0000, 0.0000, 0.6706,\n",
              "         0.8902, 0.1961, 0.1647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980,\n",
              "         0.9765, 0.5137, 0.1765, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667,\n",
              "         0.2667, 0.4157, 0.2353, 0.3451, 0.1255, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.1843,\n",
              "         0.2745, 0.7490, 0.4431, 0.0863, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.0980, 0.2941,\n",
              "         0.6902, 0.8314, 0.4235, 0.4824, 0.1373, 0.0863, 0.0275, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0980, 0.2863, 0.5804,\n",
              "         0.8196, 0.1647, 0.0000, 0.0000, 0.1255, 0.4627, 0.0196, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.3255, 0.6118,\n",
              "         0.5922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.6235, 0.1961, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0196, 0.3451, 0.6824,\n",
              "         0.4235, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.8196, 0.2863,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1059, 0.0667, 0.4627,\n",
              "         0.2157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.6627,\n",
              "         0.4627, 0.0000, 0.0000, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.6627,\n",
              "         0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.2078, 0.0392,\n",
              "         0.3059, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.8000,\n",
              "         0.5333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000,\n",
              "         0.6902, 0.4157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0275, 0.0000,\n",
              "         0.0275, 0.0196, 0.6431, 0.0078, 0.0000, 0.0000, 0.0000, 0.2941, 0.5725,\n",
              "         0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000,\n",
              "         0.0000, 0.7294, 0.4824, 0.0000, 0.1176, 0.2353, 0.0980, 0.1059, 0.2667,\n",
              "         0.3255, 0.1843, 0.2078, 0.3725, 0.1765, 0.0000, 0.0784, 0.4627, 0.6627,\n",
              "         0.6235, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.6627, 0.3333, 0.0000, 0.1059, 0.4627, 0.5216, 0.4745,\n",
              "         0.3922, 0.5412, 0.2941, 0.3137, 0.2863, 0.4745, 0.5412, 0.5412, 0.6824,\n",
              "         0.6314, 0.0078, 0.0000, 0.0196, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0078, 0.0000, 0.6235, 0.5608, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0196, 0.1176, 0.2078, 0.1961, 0.3137, 0.2549, 0.4157, 0.5137, 0.1961,\n",
              "         0.2275, 0.0000, 0.0000, 0.0000, 0.0078, 0.0275, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.5529, 0.5804, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]),\n",
              " tensor(5))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create train and test loader\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "SiAYtQinrGPk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we are doing these to reduce overfitting\n",
        "# 1) BatchNormalization\n",
        "# 2) Dropout\n",
        "# 3) L2 Regularization\n",
        "\n",
        "# to improve the accuracy\n",
        "# 1) 83% -----> when run on cpu\n",
        "# 2) 89% -----> when run on GPU -------> training acc = 98%\n",
        "# 3) 89% -----> when reduced overfit -----> training acc = 93%"
      ],
      "metadata": {
        "id": "vJT-wEvaHMmB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, num_hidden_layer, neurons_per_layer, dropout_rate):\n",
        "    super().__init__()\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    for i in range(num_hidden_layer):\n",
        "      layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
        "      layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
        "      layers.append(nn.ReLU())\n",
        "      layers.append(nn.Dropout(dropout_rate))\n",
        "      input_dim = neurons_per_layer\n",
        "\n",
        "    layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "K9F2taP6Yoq1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective function\n",
        "def objective(trial):\n",
        "  # next hyperparameter values from the search space\n",
        "  num_hidden_layer = trial.suggest_int(\"num_hidden_layer\", 1, 5)\n",
        "  neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 8, 128, step=8)\n",
        "  learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "  epochs = trial.suggest_int(\"epochs\", 10, 50, step=10)\n",
        "  dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [16,32,64,128])\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", ['adam','SGD','RMSprop'])\n",
        "  weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  # model init\n",
        "  input_dim = 784\n",
        "  output_dim = 10\n",
        "\n",
        "  model = NeuralNetwork(input_dim, output_dim, num_hidden_layer, neurons_per_layer, dropout_rate)\n",
        "  model = model.to(device)\n",
        "\n",
        "  # params init\n",
        "  # learning_rate = 0.01\n",
        "  # epochs = 50\n",
        "\n",
        "  # optimizer selection\n",
        "  criterian = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "  if optimizer_name == 'adam':\n",
        "    optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "  elif optimizer_name == 'SGD':\n",
        "    optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "  else:\n",
        "    optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "  # training loop\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    for batch_features, batch_label in train_loader:\n",
        "\n",
        "      # move to GPU\n",
        "      batch_features = batch_features.to(device)\n",
        "      batch_label = batch_label.to(device)\n",
        "\n",
        "      # forward\n",
        "      out = model(batch_features)\n",
        "\n",
        "      # loss calculation\n",
        "      loss = criterian(out, batch_label)\n",
        "\n",
        "      # back prop\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      # update grad\n",
        "      optimizer.step()\n",
        "\n",
        "  # evaluation\n",
        "  model.eval()\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch_features, batch_label in test_loader:\n",
        "      # move to GPU\n",
        "      batch_features = batch_features.to(device)\n",
        "      batch_label = batch_label.to(device)\n",
        "\n",
        "      out = model(batch_features)\n",
        "\n",
        "      _, pred = torch.max(out.data, 1)\n",
        "\n",
        "      total = total + batch_label.shape[0]\n",
        "      correct = correct + (pred == batch_label).sum().item()\n",
        "\n",
        "    accuracy = correct/total\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "MalyJj4_Wg_I"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS67vI-K0HaM",
        "outputId": "6fe5a506-fcfc-4e84-8599-bf83157666f4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "study = optuna.create_study(direction='maximize')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJAvXyEdcW2Q",
        "outputId": "35e390aa-371a-4f94-9770-f3a23d3549e7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-22 15:32:43,973] A new study created in memory with name: no-name-3f2b9823-aa51-4066-92de-fde7568874d7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAZKh9ZXc3mh",
        "outputId": "e8e3892c-01e2-4e61-d37f-54586b8ea6ff"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-22 15:37:41,698] Trial 1 finished with value: 0.7894166666666667 and parameters: {'num_hidden_layer': 5, 'neurons_per_layer': 128, 'learning_rate': 6.811862669111406e-05, 'epochs': 40, 'dropout_rate': 0.2, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 0.00030850674805956975}. Best is trial 1 with value: 0.7894166666666667.\n",
            "[I 2025-12-22 15:43:41,461] Trial 2 finished with value: 0.8869166666666667 and parameters: {'num_hidden_layer': 3, 'neurons_per_layer': 72, 'learning_rate': 0.0008981650883097245, 'epochs': 50, 'dropout_rate': 0.1, 'batch_size': 16, 'optimizer': 'adam', 'weight_decay': 0.00010262342210302129}. Best is trial 2 with value: 0.8869166666666667.\n",
            "[I 2025-12-22 15:45:45,437] Trial 3 finished with value: 0.8249166666666666 and parameters: {'num_hidden_layer': 1, 'neurons_per_layer': 32, 'learning_rate': 0.00020453242317005683, 'epochs': 50, 'dropout_rate': 0.5, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 6.0304548353419486e-05}. Best is trial 2 with value: 0.8869166666666667.\n",
            "[I 2025-12-22 15:46:48,027] Trial 4 finished with value: 0.8588333333333333 and parameters: {'num_hidden_layer': 5, 'neurons_per_layer': 48, 'learning_rate': 0.07206661065019247, 'epochs': 40, 'dropout_rate': 0.4, 'batch_size': 128, 'optimizer': 'adam', 'weight_decay': 3.549754995809325e-05}. Best is trial 2 with value: 0.8869166666666667.\n",
            "[I 2025-12-22 15:48:23,165] Trial 5 finished with value: 0.88325 and parameters: {'num_hidden_layer': 2, 'neurons_per_layer': 64, 'learning_rate': 0.003944989170654559, 'epochs': 30, 'dropout_rate': 0.2, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 0.000283153388516847}. Best is trial 2 with value: 0.8869166666666667.\n",
            "[I 2025-12-22 15:49:13,082] Trial 6 finished with value: 0.8401666666666666 and parameters: {'num_hidden_layer': 1, 'neurons_per_layer': 112, 'learning_rate': 0.0003193723888872894, 'epochs': 20, 'dropout_rate': 0.1, 'batch_size': 32, 'optimizer': 'RMSprop', 'weight_decay': 7.176070669258866e-05}. Best is trial 2 with value: 0.8869166666666667.\n",
            "[I 2025-12-22 15:51:07,231] Trial 7 finished with value: 0.8264166666666667 and parameters: {'num_hidden_layer': 3, 'neurons_per_layer': 104, 'learning_rate': 0.0004912882322756517, 'epochs': 30, 'dropout_rate': 0.5, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 3.325120358660974e-05}. Best is trial 2 with value: 0.8869166666666667.\n",
            "[I 2025-12-22 15:51:50,211] Trial 8 finished with value: 0.8874166666666666 and parameters: {'num_hidden_layer': 2, 'neurons_per_layer': 80, 'learning_rate': 0.06569254027720253, 'epochs': 40, 'dropout_rate': 0.2, 'batch_size': 128, 'optimizer': 'adam', 'weight_decay': 0.0008468918088756364}. Best is trial 8 with value: 0.8874166666666666.\n",
            "[I 2025-12-22 15:52:34,218] Trial 9 finished with value: 0.5779166666666666 and parameters: {'num_hidden_layer': 2, 'neurons_per_layer': 112, 'learning_rate': 1.1967291471780387e-05, 'epochs': 40, 'dropout_rate': 0.4, 'batch_size': 128, 'optimizer': 'SGD', 'weight_decay': 4.2619502575538816e-05}. Best is trial 8 with value: 0.8874166666666666.\n",
            "[I 2025-12-22 15:53:29,441] Trial 10 finished with value: 0.18541666666666667 and parameters: {'num_hidden_layer': 5, 'neurons_per_layer': 32, 'learning_rate': 2.002295928292056e-05, 'epochs': 20, 'dropout_rate': 0.4, 'batch_size': 64, 'optimizer': 'SGD', 'weight_decay': 5.55529057071697e-05}. Best is trial 8 with value: 0.8874166666666666.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_trial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYn3iIf1divd",
        "outputId": "8ebbc02b-a44f-46f2-9d69-cae0e08bbf74"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenTrial(number=8, state=<TrialState.COMPLETE: 1>, values=[0.8874166666666666], datetime_start=datetime.datetime(2025, 12, 22, 15, 51, 7, 232158), datetime_complete=datetime.datetime(2025, 12, 22, 15, 51, 50, 211710), params={'num_hidden_layer': 2, 'neurons_per_layer': 80, 'learning_rate': 0.06569254027720253, 'epochs': 40, 'dropout_rate': 0.2, 'batch_size': 128, 'optimizer': 'adam', 'weight_decay': 0.0008468918088756364}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'num_hidden_layer': IntDistribution(high=5, log=False, low=1, step=1), 'neurons_per_layer': IntDistribution(high=128, log=False, low=8, step=8), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'epochs': IntDistribution(high=50, log=False, low=10, step=10), 'dropout_rate': FloatDistribution(high=0.5, log=False, low=0.1, step=0.1), 'batch_size': CategoricalDistribution(choices=(16, 32, 64, 128)), 'optimizer': CategoricalDistribution(choices=('adam', 'SGD', 'RMSprop')), 'weight_decay': FloatDistribution(high=0.001, log=True, low=1e-05, step=None)}, trial_id=8, value=None)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKRZZGBNmqPr",
        "outputId": "e61df68b-7456-47ab-c941-5ca43f666ac7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_hidden_layer': 2,\n",
              " 'neurons_per_layer': 80,\n",
              " 'learning_rate': 0.06569254027720253,\n",
              " 'epochs': 40,\n",
              " 'dropout_rate': 0.2,\n",
              " 'batch_size': 128,\n",
              " 'optimizer': 'adam',\n",
              " 'weight_decay': 0.0008468918088756364}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TWr8ibzIm1uX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}