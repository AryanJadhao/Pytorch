{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOuFzFToRA7Nj4NxQSbHW+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryanJadhao/Pytorch/blob/main/Next_Word_Predictor_pytorch_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNSkmaBwafxP",
        "outputId": "0a6eabeb-77e4-4e81-916c-483d0586f116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "lopWv8sNaj0R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every paid session once you become a paid user.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at nitish.campusx@gmail.com\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "Can we pay the entire amount of Rs 5600 all at once?\n",
        "Unfortunately no, the program follows a monthly subscription model.\n",
        "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
        "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 5600\n",
        "You have to attempt all the course assessments.\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "n7HLxzUHa_as"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr1NKCdDbOzK",
        "outputId": "6d052114-ecdd-4e44-9b5a-24fb8033b9c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "z_Cv_BiLbav7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab\n",
        "vocab = {'<UNK>':0}\n",
        "\n",
        "Counter(tokens).keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i12mbhaSblrp",
        "outputId": "96a80ab2-c74d-418f-9426-8415715ebeb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['about', 'the', 'program', 'what', 'is', 'course', 'fee', 'for', 'data', 'science', 'mentorship', '(', 'dsmp', '2023', ')', 'follows', 'a', 'monthly', 'subscription', 'model', 'where', 'you', 'have', 'to', 'make', 'payments', 'of', 'rs', '799/month', '.', 'total', 'duration', '?', '7', 'months', 'so', 'becomes', '799', '*', '=', '5600', 'approx', 'syllabus', 'we', 'will', 'be', 'covering', 'following', 'modules', ':', 'python', 'fundamentals', 'libraries', 'analysis', 'sql', 'maths', 'machine', 'learning', 'ml', 'algorithms', 'practical', 'mlops', 'case', 'studies', 'can', 'check', 'detailed', 'here', '-', 'https', '//learnwith.campusx.in/courses/campusx-data-science-mentorship-program-637339afe4b0615a1bbed390', 'deep', 'and', 'nlp', 'part', 'this', 'no', ',', 'both', 'are', 'not', '’', 's', 'curriculum', 'if', 'i', 'miss', 'live', 'session', 'get', 'recording', 'yes', 'all', 'our', 'sessions', 'recorded', 'even', 'go', 'back', 'watch', 'find', 'class', 'schedule', 'checkout', 'google', 'sheet', 'see', 'month', 'by', 'time', 'table', '//docs.google.com/spreadsheets/d/16ootax_a6oraecg4emgexhqqpv3noqpyku7rj6arozk/edit', 'usp=sharing', 'roughly', 'last', '2', 'hours', 'language', 'spoken', 'instructor', 'during', 'hinglish', 'how', 'informed', 'upcoming', 'mail', 'from', 'side', 'before', 'every', 'paid', 'once', 'become', 'user', 'do', 'am', 'non-tech', 'background', 'absolutely', 'late', 'join', 'in', 'middle', 'anytime', 'join/pay', 'able', 'past', 'lectures', 'payment', 'content', 'your', 'dashboard', 'submit', 'task', 'don', 't', 'provide', 'with', 'solutions', 'self', 'evaluate', 'yourself', 'contact', 'us', 'at', 'nitish.campusx', '@', 'gmail.com', 'payment/registration', 'related', 'questions', 'youtube', 'channel', 'or', 'website', 'on', 'link', '//learnwith.campusx.in/', 'pay', 'entire', 'amount', 'unfortunately', 'validity', 'suppose', '15th', 'jan', 'then', 'again', '1st', 'feb', 'feb.', 'period', '30', 'days', 'day', 'essentially', 'wait', 'end', 'like', 'after', 'making', 'refund', 'policy', 'made', 'living', 'outside', 'india', 'should', 'sending', 'post', 'registration', 'queries', 'till', 'when', 'view', 'videos', 'one', 'tricky', 'read', 'carefully', 'valid', 'purchased', '21st', '20th', 'but', 'purchase', 'over', 'installments', 'aug', '2024.', 'why', 'lifetime', 'provided', 'because', 'low', 'reach', 'out', 'doubt', 'fill', 'form', 'team', '1', 'clearance', 'still', 'ask', 'week', 'doubts', 'just', 'select', 'gmai.com', 'certificate', 'placement', 'assistance', 'criteria', 'there', 'criterias', 'attempt', 'assessments', 'joining', 'earlier', 'current', 'that', 'comes', 'under', 'clarify', 'does', 'mean', 'guarantee', 'dont', 'any', 'jobs', 'matter', 'interview', 'calls', 'planning', 'placements', 'afraid', 'disappointed', 'portfolio', 'building', 'soft', 'skill', 'industry', 'mentors', 'discussion', 'job', 'hunting', 'strategies'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qTZtxMsMb2J7",
        "outputId": "d34c573c-deda-467e-e7d7-b61ea269b7d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0,\n",
              " 'about': 1,\n",
              " 'the': 2,\n",
              " 'program': 3,\n",
              " 'what': 4,\n",
              " 'is': 5,\n",
              " 'course': 6,\n",
              " 'fee': 7,\n",
              " 'for': 8,\n",
              " 'data': 9,\n",
              " 'science': 10,\n",
              " 'mentorship': 11,\n",
              " '(': 12,\n",
              " 'dsmp': 13,\n",
              " '2023': 14,\n",
              " ')': 15,\n",
              " 'follows': 16,\n",
              " 'a': 17,\n",
              " 'monthly': 18,\n",
              " 'subscription': 19,\n",
              " 'model': 20,\n",
              " 'where': 21,\n",
              " 'you': 22,\n",
              " 'have': 23,\n",
              " 'to': 24,\n",
              " 'make': 25,\n",
              " 'payments': 26,\n",
              " 'of': 27,\n",
              " 'rs': 28,\n",
              " '799/month': 29,\n",
              " '.': 30,\n",
              " 'total': 31,\n",
              " 'duration': 32,\n",
              " '?': 33,\n",
              " '7': 34,\n",
              " 'months': 35,\n",
              " 'so': 36,\n",
              " 'becomes': 37,\n",
              " '799': 38,\n",
              " '*': 39,\n",
              " '=': 40,\n",
              " '5600': 41,\n",
              " 'approx': 42,\n",
              " 'syllabus': 43,\n",
              " 'we': 44,\n",
              " 'will': 45,\n",
              " 'be': 46,\n",
              " 'covering': 47,\n",
              " 'following': 48,\n",
              " 'modules': 49,\n",
              " ':': 50,\n",
              " 'python': 51,\n",
              " 'fundamentals': 52,\n",
              " 'libraries': 53,\n",
              " 'analysis': 54,\n",
              " 'sql': 55,\n",
              " 'maths': 56,\n",
              " 'machine': 57,\n",
              " 'learning': 58,\n",
              " 'ml': 59,\n",
              " 'algorithms': 60,\n",
              " 'practical': 61,\n",
              " 'mlops': 62,\n",
              " 'case': 63,\n",
              " 'studies': 64,\n",
              " 'can': 65,\n",
              " 'check': 66,\n",
              " 'detailed': 67,\n",
              " 'here': 68,\n",
              " '-': 69,\n",
              " 'https': 70,\n",
              " '//learnwith.campusx.in/courses/campusx-data-science-mentorship-program-637339afe4b0615a1bbed390': 71,\n",
              " 'deep': 72,\n",
              " 'and': 73,\n",
              " 'nlp': 74,\n",
              " 'part': 75,\n",
              " 'this': 76,\n",
              " 'no': 77,\n",
              " ',': 78,\n",
              " 'both': 79,\n",
              " 'are': 80,\n",
              " 'not': 81,\n",
              " '’': 82,\n",
              " 's': 83,\n",
              " 'curriculum': 84,\n",
              " 'if': 85,\n",
              " 'i': 86,\n",
              " 'miss': 87,\n",
              " 'live': 88,\n",
              " 'session': 89,\n",
              " 'get': 90,\n",
              " 'recording': 91,\n",
              " 'yes': 92,\n",
              " 'all': 93,\n",
              " 'our': 94,\n",
              " 'sessions': 95,\n",
              " 'recorded': 96,\n",
              " 'even': 97,\n",
              " 'go': 98,\n",
              " 'back': 99,\n",
              " 'watch': 100,\n",
              " 'find': 101,\n",
              " 'class': 102,\n",
              " 'schedule': 103,\n",
              " 'checkout': 104,\n",
              " 'google': 105,\n",
              " 'sheet': 106,\n",
              " 'see': 107,\n",
              " 'month': 108,\n",
              " 'by': 109,\n",
              " 'time': 110,\n",
              " 'table': 111,\n",
              " '//docs.google.com/spreadsheets/d/16ootax_a6oraecg4emgexhqqpv3noqpyku7rj6arozk/edit': 112,\n",
              " 'usp=sharing': 113,\n",
              " 'roughly': 114,\n",
              " 'last': 115,\n",
              " '2': 116,\n",
              " 'hours': 117,\n",
              " 'language': 118,\n",
              " 'spoken': 119,\n",
              " 'instructor': 120,\n",
              " 'during': 121,\n",
              " 'hinglish': 122,\n",
              " 'how': 123,\n",
              " 'informed': 124,\n",
              " 'upcoming': 125,\n",
              " 'mail': 126,\n",
              " 'from': 127,\n",
              " 'side': 128,\n",
              " 'before': 129,\n",
              " 'every': 130,\n",
              " 'paid': 131,\n",
              " 'once': 132,\n",
              " 'become': 133,\n",
              " 'user': 134,\n",
              " 'do': 135,\n",
              " 'am': 136,\n",
              " 'non-tech': 137,\n",
              " 'background': 138,\n",
              " 'absolutely': 139,\n",
              " 'late': 140,\n",
              " 'join': 141,\n",
              " 'in': 142,\n",
              " 'middle': 143,\n",
              " 'anytime': 144,\n",
              " 'join/pay': 145,\n",
              " 'able': 146,\n",
              " 'past': 147,\n",
              " 'lectures': 148,\n",
              " 'payment': 149,\n",
              " 'content': 150,\n",
              " 'your': 151,\n",
              " 'dashboard': 152,\n",
              " 'submit': 153,\n",
              " 'task': 154,\n",
              " 'don': 155,\n",
              " 't': 156,\n",
              " 'provide': 157,\n",
              " 'with': 158,\n",
              " 'solutions': 159,\n",
              " 'self': 160,\n",
              " 'evaluate': 161,\n",
              " 'yourself': 162,\n",
              " 'contact': 163,\n",
              " 'us': 164,\n",
              " 'at': 165,\n",
              " 'nitish.campusx': 166,\n",
              " '@': 167,\n",
              " 'gmail.com': 168,\n",
              " 'payment/registration': 169,\n",
              " 'related': 170,\n",
              " 'questions': 171,\n",
              " 'youtube': 172,\n",
              " 'channel': 173,\n",
              " 'or': 174,\n",
              " 'website': 175,\n",
              " 'on': 176,\n",
              " 'link': 177,\n",
              " '//learnwith.campusx.in/': 178,\n",
              " 'pay': 179,\n",
              " 'entire': 180,\n",
              " 'amount': 181,\n",
              " 'unfortunately': 182,\n",
              " 'validity': 183,\n",
              " 'suppose': 184,\n",
              " '15th': 185,\n",
              " 'jan': 186,\n",
              " 'then': 187,\n",
              " 'again': 188,\n",
              " '1st': 189,\n",
              " 'feb': 190,\n",
              " 'feb.': 191,\n",
              " 'period': 192,\n",
              " '30': 193,\n",
              " 'days': 194,\n",
              " 'day': 195,\n",
              " 'essentially': 196,\n",
              " 'wait': 197,\n",
              " 'end': 198,\n",
              " 'like': 199,\n",
              " 'after': 200,\n",
              " 'making': 201,\n",
              " 'refund': 202,\n",
              " 'policy': 203,\n",
              " 'made': 204,\n",
              " 'living': 205,\n",
              " 'outside': 206,\n",
              " 'india': 207,\n",
              " 'should': 208,\n",
              " 'sending': 209,\n",
              " 'post': 210,\n",
              " 'registration': 211,\n",
              " 'queries': 212,\n",
              " 'till': 213,\n",
              " 'when': 214,\n",
              " 'view': 215,\n",
              " 'videos': 216,\n",
              " 'one': 217,\n",
              " 'tricky': 218,\n",
              " 'read': 219,\n",
              " 'carefully': 220,\n",
              " 'valid': 221,\n",
              " 'purchased': 222,\n",
              " '21st': 223,\n",
              " '20th': 224,\n",
              " 'but': 225,\n",
              " 'purchase': 226,\n",
              " 'over': 227,\n",
              " 'installments': 228,\n",
              " 'aug': 229,\n",
              " '2024.': 230,\n",
              " 'why': 231,\n",
              " 'lifetime': 232,\n",
              " 'provided': 233,\n",
              " 'because': 234,\n",
              " 'low': 235,\n",
              " 'reach': 236,\n",
              " 'out': 237,\n",
              " 'doubt': 238,\n",
              " 'fill': 239,\n",
              " 'form': 240,\n",
              " 'team': 241,\n",
              " '1': 242,\n",
              " 'clearance': 243,\n",
              " 'still': 244,\n",
              " 'ask': 245,\n",
              " 'week': 246,\n",
              " 'doubts': 247,\n",
              " 'just': 248,\n",
              " 'select': 249,\n",
              " 'gmai.com': 250,\n",
              " 'certificate': 251,\n",
              " 'placement': 252,\n",
              " 'assistance': 253,\n",
              " 'criteria': 254,\n",
              " 'there': 255,\n",
              " 'criterias': 256,\n",
              " 'attempt': 257,\n",
              " 'assessments': 258,\n",
              " 'joining': 259,\n",
              " 'earlier': 260,\n",
              " 'current': 261,\n",
              " 'that': 262,\n",
              " 'comes': 263,\n",
              " 'under': 264,\n",
              " 'clarify': 265,\n",
              " 'does': 266,\n",
              " 'mean': 267,\n",
              " 'guarantee': 268,\n",
              " 'dont': 269,\n",
              " 'any': 270,\n",
              " 'jobs': 271,\n",
              " 'matter': 272,\n",
              " 'interview': 273,\n",
              " 'calls': 274,\n",
              " 'planning': 275,\n",
              " 'placements': 276,\n",
              " 'afraid': 277,\n",
              " 'disappointed': 278,\n",
              " 'portfolio': 279,\n",
              " 'building': 280,\n",
              " 'soft': 281,\n",
              " 'skill': 282,\n",
              " 'industry': 283,\n",
              " 'mentors': 284,\n",
              " 'discussion': 285,\n",
              " 'job': 286,\n",
              " 'hunting': 287,\n",
              " 'strategies': 288}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuFfJ9QOcR26",
        "outputId": "db5409bf-0b1f-43e7-d9b6-6ac2669cfcff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "zO0qPPcbcYxN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence,vocab):\n",
        "  numerical_sentence = []\n",
        "\n",
        "  for token in sentence:\n",
        "    if token not in vocab:\n",
        "      numerical_sentence.append(vocab['<UNK>'])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "\n",
        "  return numerical_sentence"
      ],
      "metadata": {
        "id": "drwnxMU2dkAH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numeric_sentence = []\n",
        "for sentence in input_sentences:\n",
        "\n",
        "  input_numeric_sentence.append(text_to_indices(word_tokenize(sentence.lower()),vocab))"
      ],
      "metadata": {
        "id": "151Oralkcw2A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numeric_sentence"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnZlvRNGePJS",
        "outputId": "a1de9338-6d7f-49d8-89c7-460292ce8144"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3],\n",
              " [4, 5, 2, 6, 7, 8, 9, 10, 11, 3, 12, 13, 14, 15],\n",
              " [2, 6, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 18, 26, 27, 28, 29, 30],\n",
              " [4, 5, 2, 31, 32, 27, 2, 6, 33],\n",
              " [2,\n",
              "  31,\n",
              "  32,\n",
              "  27,\n",
              "  2,\n",
              "  6,\n",
              "  5,\n",
              "  34,\n",
              "  35,\n",
              "  30,\n",
              "  36,\n",
              "  2,\n",
              "  31,\n",
              "  6,\n",
              "  7,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  34,\n",
              "  40,\n",
              "  28,\n",
              "  41,\n",
              "  12,\n",
              "  42,\n",
              "  30,\n",
              "  15],\n",
              " [4, 5, 2, 43, 27, 2, 11, 3, 33],\n",
              " [44, 45, 46, 47, 2, 48, 49, 50],\n",
              " [51, 52],\n",
              " [51, 53, 8, 9, 10],\n",
              " [9, 54],\n",
              " [55, 8, 9, 10],\n",
              " [56, 8, 57, 58],\n",
              " [59, 60],\n",
              " [61, 59],\n",
              " [62],\n",
              " [63, 64],\n",
              " [22, 65, 66, 2, 67, 43, 68, 69, 70, 50, 71],\n",
              " [45, 72, 58, 73, 74, 46, 17, 75, 27, 76, 3, 33],\n",
              " [77, 78, 74, 73, 72, 58, 79, 80, 81, 17, 75, 27, 76, 3, 82, 83, 84, 30],\n",
              " [4, 85, 86, 87, 17, 88, 89, 33, 45, 86, 90, 17, 91, 27, 2, 89, 33],\n",
              " [92,\n",
              "  93,\n",
              "  94,\n",
              "  95,\n",
              "  80,\n",
              "  96,\n",
              "  78,\n",
              "  36,\n",
              "  97,\n",
              "  85,\n",
              "  22,\n",
              "  87,\n",
              "  17,\n",
              "  89,\n",
              "  22,\n",
              "  65,\n",
              "  98,\n",
              "  99,\n",
              "  73,\n",
              "  100,\n",
              "  2,\n",
              "  91,\n",
              "  30],\n",
              " [21, 65, 86, 101, 2, 102, 103, 33],\n",
              " [104,\n",
              "  76,\n",
              "  105,\n",
              "  106,\n",
              "  24,\n",
              "  107,\n",
              "  108,\n",
              "  109,\n",
              "  108,\n",
              "  110,\n",
              "  111,\n",
              "  27,\n",
              "  2,\n",
              "  6,\n",
              "  69,\n",
              "  70,\n",
              "  50,\n",
              "  112,\n",
              "  33,\n",
              "  113,\n",
              "  30],\n",
              " [4, 5, 2, 110, 32, 27, 93, 2, 88, 95, 33],\n",
              " [114, 78, 93, 2, 95, 115, 116, 117, 30],\n",
              " [4, 5, 2, 118, 119, 109, 2, 120, 121, 2, 95, 33],\n",
              " [122],\n",
              " [123, 45, 86, 46, 124, 1, 2, 125, 102, 33],\n",
              " [22,\n",
              "  45,\n",
              "  90,\n",
              "  17,\n",
              "  126,\n",
              "  127,\n",
              "  94,\n",
              "  128,\n",
              "  129,\n",
              "  130,\n",
              "  131,\n",
              "  89,\n",
              "  132,\n",
              "  22,\n",
              "  133,\n",
              "  17,\n",
              "  131,\n",
              "  134,\n",
              "  30],\n",
              " [65, 86, 135, 76, 6, 85, 86, 136, 127, 17, 137, 138, 33],\n",
              " [92, 78, 139, 30],\n",
              " [86, 136, 140, 78, 65, 86, 141, 2, 3, 142, 2, 143, 33],\n",
              " [139, 78, 22, 65, 141, 2, 3, 144, 30],\n",
              " [85, 86, 145, 142, 2, 143, 78, 45, 86, 46, 146, 24, 107, 93, 2, 147, 148, 33],\n",
              " [92,\n",
              "  78,\n",
              "  132,\n",
              "  22,\n",
              "  25,\n",
              "  2,\n",
              "  149,\n",
              "  22,\n",
              "  45,\n",
              "  46,\n",
              "  146,\n",
              "  24,\n",
              "  107,\n",
              "  93,\n",
              "  2,\n",
              "  147,\n",
              "  150,\n",
              "  142,\n",
              "  151,\n",
              "  152,\n",
              "  30],\n",
              " [21, 135, 86, 23, 24, 153, 2, 154, 33],\n",
              " [22,\n",
              "  155,\n",
              "  82,\n",
              "  156,\n",
              "  23,\n",
              "  24,\n",
              "  153,\n",
              "  2,\n",
              "  154,\n",
              "  30,\n",
              "  44,\n",
              "  45,\n",
              "  157,\n",
              "  22,\n",
              "  158,\n",
              "  2,\n",
              "  159,\n",
              "  78,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  160,\n",
              "  161,\n",
              "  2,\n",
              "  154,\n",
              "  162,\n",
              "  30],\n",
              " [45, 44, 135, 63, 64, 142, 2, 3, 33],\n",
              " [92, 30],\n",
              " [21, 65, 44, 163, 22, 33],\n",
              " [22, 65, 126, 164, 165, 166, 167, 168],\n",
              " [169, 170, 171],\n",
              " [21, 135, 44, 23, 24, 25, 94, 26, 33, 151, 172, 173, 174, 175, 33],\n",
              " [22,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  93,\n",
              "  151,\n",
              "  18,\n",
              "  26,\n",
              "  176,\n",
              "  94,\n",
              "  175,\n",
              "  30,\n",
              "  68,\n",
              "  5,\n",
              "  2,\n",
              "  177,\n",
              "  8,\n",
              "  94,\n",
              "  175,\n",
              "  69,\n",
              "  70,\n",
              "  50,\n",
              "  178],\n",
              " [65, 44, 179, 2, 180, 181, 27, 28, 41, 93, 165, 132, 33],\n",
              " [182, 77, 78, 2, 3, 16, 17, 18, 19, 20, 30],\n",
              " [4,\n",
              "  5,\n",
              "  2,\n",
              "  183,\n",
              "  27,\n",
              "  18,\n",
              "  19,\n",
              "  33,\n",
              "  184,\n",
              "  85,\n",
              "  86,\n",
              "  179,\n",
              "  176,\n",
              "  185,\n",
              "  186,\n",
              "  78,\n",
              "  187,\n",
              "  135,\n",
              "  86,\n",
              "  23,\n",
              "  24,\n",
              "  179,\n",
              "  188,\n",
              "  176,\n",
              "  189,\n",
              "  190,\n",
              "  174,\n",
              "  185,\n",
              "  190],\n",
              " [185,\n",
              "  191,\n",
              "  2,\n",
              "  183,\n",
              "  192,\n",
              "  5,\n",
              "  193,\n",
              "  194,\n",
              "  127,\n",
              "  2,\n",
              "  195,\n",
              "  22,\n",
              "  25,\n",
              "  2,\n",
              "  149,\n",
              "  30,\n",
              "  36,\n",
              "  196,\n",
              "  22,\n",
              "  65,\n",
              "  141,\n",
              "  144,\n",
              "  22,\n",
              "  155,\n",
              "  82,\n",
              "  156,\n",
              "  23,\n",
              "  24,\n",
              "  197,\n",
              "  8,\n",
              "  17,\n",
              "  108,\n",
              "  24,\n",
              "  198,\n",
              "  30],\n",
              " [4,\n",
              "  85,\n",
              "  86,\n",
              "  155,\n",
              "  82,\n",
              "  156,\n",
              "  199,\n",
              "  2,\n",
              "  6,\n",
              "  200,\n",
              "  201,\n",
              "  2,\n",
              "  149,\n",
              "  30,\n",
              "  4,\n",
              "  5,\n",
              "  2,\n",
              "  202,\n",
              "  203,\n",
              "  33],\n",
              " [22, 90, 17, 34, 194, 202, 192, 127, 2, 195, 22, 23, 204, 2, 149, 30],\n",
              " [86,\n",
              "  136,\n",
              "  205,\n",
              "  206,\n",
              "  207,\n",
              "  73,\n",
              "  86,\n",
              "  136,\n",
              "  81,\n",
              "  146,\n",
              "  24,\n",
              "  25,\n",
              "  2,\n",
              "  149,\n",
              "  176,\n",
              "  2,\n",
              "  175,\n",
              "  78,\n",
              "  4,\n",
              "  208,\n",
              "  86,\n",
              "  135,\n",
              "  33],\n",
              " [22, 23, 24, 163, 164, 109, 209, 17, 126, 165, 166, 167, 168],\n",
              " [210, 211, 212],\n",
              " [213, 214, 65, 86, 215, 2, 131, 216, 176, 2, 175, 33],\n",
              " [76,\n",
              "  217,\n",
              "  5,\n",
              "  218,\n",
              "  78,\n",
              "  36,\n",
              "  219,\n",
              "  220,\n",
              "  30,\n",
              "  22,\n",
              "  65,\n",
              "  100,\n",
              "  2,\n",
              "  216,\n",
              "  213,\n",
              "  151,\n",
              "  19,\n",
              "  5,\n",
              "  221,\n",
              "  30,\n",
              "  184,\n",
              "  22,\n",
              "  23,\n",
              "  222,\n",
              "  19,\n",
              "  176,\n",
              "  223,\n",
              "  186,\n",
              "  78,\n",
              "  22,\n",
              "  45,\n",
              "  46,\n",
              "  146,\n",
              "  24,\n",
              "  100,\n",
              "  93,\n",
              "  2,\n",
              "  147,\n",
              "  131,\n",
              "  95,\n",
              "  142,\n",
              "  2,\n",
              "  192,\n",
              "  27,\n",
              "  223,\n",
              "  186,\n",
              "  24,\n",
              "  224,\n",
              "  191,\n",
              "  225,\n",
              "  200,\n",
              "  223,\n",
              "  190,\n",
              "  22,\n",
              "  45,\n",
              "  23,\n",
              "  24,\n",
              "  226,\n",
              "  2,\n",
              "  19,\n",
              "  188,\n",
              "  30],\n",
              " [225,\n",
              "  132,\n",
              "  2,\n",
              "  6,\n",
              "  5,\n",
              "  227,\n",
              "  73,\n",
              "  22,\n",
              "  23,\n",
              "  131,\n",
              "  164,\n",
              "  28,\n",
              "  41,\n",
              "  12,\n",
              "  174,\n",
              "  34,\n",
              "  228,\n",
              "  27,\n",
              "  28,\n",
              "  38,\n",
              "  15,\n",
              "  22,\n",
              "  45,\n",
              "  46,\n",
              "  146,\n",
              "  24,\n",
              "  100,\n",
              "  2,\n",
              "  131,\n",
              "  95,\n",
              "  213,\n",
              "  229,\n",
              "  0,\n",
              "  30],\n",
              " [231, 232, 183, 5, 81, 233, 33],\n",
              " [234, 27, 2, 235, 6, 7, 30],\n",
              " [21, 65, 86, 236, 237, 142, 63, 27, 17, 238, 200, 2, 89, 33],\n",
              " [22,\n",
              "  45,\n",
              "  23,\n",
              "  24,\n",
              "  239,\n",
              "  17,\n",
              "  105,\n",
              "  240,\n",
              "  233,\n",
              "  142,\n",
              "  151,\n",
              "  152,\n",
              "  73,\n",
              "  94,\n",
              "  241,\n",
              "  45,\n",
              "  163,\n",
              "  22,\n",
              "  8,\n",
              "  17,\n",
              "  242,\n",
              "  176,\n",
              "  242,\n",
              "  238,\n",
              "  243,\n",
              "  89],\n",
              " [85, 86, 141, 2, 3, 140, 78, 65, 86, 244, 245, 147, 246, 247, 33],\n",
              " [92, 78, 248, 249, 147, 246, 238, 142, 2, 238, 243, 105, 240, 30],\n",
              " [86,\n",
              "  136,\n",
              "  205,\n",
              "  206,\n",
              "  207,\n",
              "  73,\n",
              "  86,\n",
              "  136,\n",
              "  81,\n",
              "  146,\n",
              "  24,\n",
              "  25,\n",
              "  2,\n",
              "  149,\n",
              "  176,\n",
              "  2,\n",
              "  175,\n",
              "  78,\n",
              "  4,\n",
              "  208,\n",
              "  86,\n",
              "  135,\n",
              "  33],\n",
              " [22, 23, 24, 163, 164, 109, 209, 17, 126, 165, 166, 167, 250],\n",
              " [251, 73, 252, 253, 170, 212],\n",
              " [4, 5, 2, 254, 24, 90, 2, 251, 33],\n",
              " [255, 80, 116, 256, 50],\n",
              " [22, 23, 24, 179, 2, 180, 7, 27, 28, 41],\n",
              " [22, 23, 24, 257, 93, 2, 6, 258, 30],\n",
              " [86, 136, 259, 140, 30, 123, 65, 86, 179, 149, 27, 2, 260, 35, 33],\n",
              " [22,\n",
              "  45,\n",
              "  90,\n",
              "  17,\n",
              "  177,\n",
              "  24,\n",
              "  179,\n",
              "  7,\n",
              "  27,\n",
              "  260,\n",
              "  35,\n",
              "  142,\n",
              "  151,\n",
              "  152,\n",
              "  132,\n",
              "  22,\n",
              "  179,\n",
              "  8,\n",
              "  2,\n",
              "  261,\n",
              "  108,\n",
              "  30],\n",
              " [86,\n",
              "  23,\n",
              "  219,\n",
              "  262,\n",
              "  252,\n",
              "  253,\n",
              "  5,\n",
              "  17,\n",
              "  75,\n",
              "  27,\n",
              "  76,\n",
              "  3,\n",
              "  30,\n",
              "  4,\n",
              "  263,\n",
              "  264,\n",
              "  252,\n",
              "  253,\n",
              "  33],\n",
              " [76,\n",
              "  5,\n",
              "  24,\n",
              "  265,\n",
              "  262,\n",
              "  252,\n",
              "  253,\n",
              "  266,\n",
              "  81,\n",
              "  267,\n",
              "  252,\n",
              "  268,\n",
              "  30,\n",
              "  36,\n",
              "  44,\n",
              "  269,\n",
              "  268,\n",
              "  22,\n",
              "  270,\n",
              "  271,\n",
              "  174,\n",
              "  8,\n",
              "  262,\n",
              "  272,\n",
              "  97,\n",
              "  273,\n",
              "  274,\n",
              "  30,\n",
              "  36,\n",
              "  85,\n",
              "  22,\n",
              "  80,\n",
              "  275,\n",
              "  24,\n",
              "  141,\n",
              "  76,\n",
              "  6,\n",
              "  248,\n",
              "  8,\n",
              "  276,\n",
              "  78,\n",
              "  86,\n",
              "  136,\n",
              "  277,\n",
              "  22,\n",
              "  45,\n",
              "  46,\n",
              "  278,\n",
              "  30,\n",
              "  68,\n",
              "  5,\n",
              "  4,\n",
              "  263,\n",
              "  264,\n",
              "  252,\n",
              "  253],\n",
              " [279, 280, 95],\n",
              " [281, 282, 95],\n",
              " [95, 158, 283, 284],\n",
              " [285, 176, 286, 287, 288],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numeric_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0BJDInDeQsI",
        "outputId": "f0eb671e-4c37-4f3c-939b-94969c2809c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_seq = []\n",
        "for sentence in input_numeric_sentence:\n",
        "\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_seq.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "XeethL0BeVjW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjel7pkgqpSJ",
        "outputId": "5dbece8f-a339-4e96-9b91-8a519ddb65f9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "942"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding\n",
        "max_len = 0\n",
        "for seq in training_seq:\n",
        "  if len(seq) > max_len:\n",
        "    max_len = len(seq)\n",
        "\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ-wzwj4qqXv",
        "outputId": "32a146fc-4f27-423a-a301-18a26a009c75"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_seq = []\n",
        "for seq in training_seq:\n",
        "  padded_training_seq.append([0]*(max_len-len(seq)) + seq)"
      ],
      "metadata": {
        "id": "be7hvQMzrs-6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_seq[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ei6yWPjgsDb-",
        "outputId": "19bef243-c7c5-477e-c64e-d406f9e775b2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 6]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_seq = torch.tensor(padded_training_seq, dtype=torch.long)"
      ],
      "metadata": {
        "id": "OZYwVvbfsFJ-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saus_DZdsa6V",
        "outputId": "6e5187f6-731f-494c-b982-5499f8bfe567"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        [  0,   0,   0,  ...,   0,   4,   5],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287],\n",
              "        [  0,   0,   0,  ..., 286, 287, 288]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_seq[:,:-1]\n",
        "y = padded_training_seq[:,-1]"
      ],
      "metadata": {
        "id": "iHmANBdFscGK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Y8g-5Zstom",
        "outputId": "3cf3da24-d6fc-400a-ddf8-ab8c7fbb4363"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   0,   0,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0, 285, 176],\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6vENPv3csuRd",
        "outputId": "51da9ce9-7b95-473a-af6c-c6b277137de9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   3,   5,   2,   6,   7,   8,   9,  10,  11,   3,  12,  13,  14,\n",
              "         15,   6,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  18,  26,\n",
              "         27,  28,  29,  30,   5,   2,  31,  32,  27,   2,   6,  33,  31,  32,\n",
              "         27,   2,   6,   5,  34,  35,  30,  36,   2,  31,   6,   7,  37,  38,\n",
              "         39,  34,  40,  28,  41,  12,  42,  30,  15,   5,   2,  43,  27,   2,\n",
              "         11,   3,  33,  45,  46,  47,   2,  48,  49,  50,  52,  53,   8,   9,\n",
              "         10,  54,   8,   9,  10,   8,  57,  58,  60,  59,  64,  65,  66,   2,\n",
              "         67,  43,  68,  69,  70,  50,  71,  72,  58,  73,  74,  46,  17,  75,\n",
              "         27,  76,   3,  33,  78,  74,  73,  72,  58,  79,  80,  81,  17,  75,\n",
              "         27,  76,   3,  82,  83,  84,  30,  85,  86,  87,  17,  88,  89,  33,\n",
              "         45,  86,  90,  17,  91,  27,   2,  89,  33,  93,  94,  95,  80,  96,\n",
              "         78,  36,  97,  85,  22,  87,  17,  89,  22,  65,  98,  99,  73, 100,\n",
              "          2,  91,  30,  65,  86, 101,   2, 102, 103,  33,  76, 105, 106,  24,\n",
              "        107, 108, 109, 108, 110, 111,  27,   2,   6,  69,  70,  50, 112,  33,\n",
              "        113,  30,   5,   2, 110,  32,  27,  93,   2,  88,  95,  33,  78,  93,\n",
              "          2,  95, 115, 116, 117,  30,   5,   2, 118, 119, 109,   2, 120, 121,\n",
              "          2,  95,  33,  45,  86,  46, 124,   1,   2, 125, 102,  33,  45,  90,\n",
              "         17, 126, 127,  94, 128, 129, 130, 131,  89, 132,  22, 133,  17, 131,\n",
              "        134,  30,  86, 135,  76,   6,  85,  86, 136, 127,  17, 137, 138,  33,\n",
              "         78, 139,  30, 136, 140,  78,  65,  86, 141,   2,   3, 142,   2, 143,\n",
              "         33,  78,  22,  65, 141,   2,   3, 144,  30,  86, 145, 142,   2, 143,\n",
              "         78,  45,  86,  46, 146,  24, 107,  93,   2, 147, 148,  33,  78, 132,\n",
              "         22,  25,   2, 149,  22,  45,  46, 146,  24, 107,  93,   2, 147, 150,\n",
              "        142, 151, 152,  30, 135,  86,  23,  24, 153,   2, 154,  33, 155,  82,\n",
              "        156,  23,  24, 153,   2, 154,  30,  44,  45, 157,  22, 158,   2, 159,\n",
              "         78,  22,  23,  24, 160, 161,   2, 154, 162,  30,  44, 135,  63,  64,\n",
              "        142,   2,   3,  33,  30,  65,  44, 163,  22,  33,  65, 126, 164, 165,\n",
              "        166, 167, 168, 170, 171, 135,  44,  23,  24,  25,  94,  26,  33, 151,\n",
              "        172, 173, 174, 175,  33,  23,  24,  25,  93, 151,  18,  26, 176,  94,\n",
              "        175,  30,  68,   5,   2, 177,   8,  94, 175,  69,  70,  50, 178,  44,\n",
              "        179,   2, 180, 181,  27,  28,  41,  93, 165, 132,  33,  77,  78,   2,\n",
              "          3,  16,  17,  18,  19,  20,  30,   5,   2, 183,  27,  18,  19,  33,\n",
              "        184,  85,  86, 179, 176, 185, 186,  78, 187, 135,  86,  23,  24, 179,\n",
              "        188, 176, 189, 190, 174, 185, 190, 191,   2, 183, 192,   5, 193, 194,\n",
              "        127,   2, 195,  22,  25,   2, 149,  30,  36, 196,  22,  65, 141, 144,\n",
              "         22, 155,  82, 156,  23,  24, 197,   8,  17, 108,  24, 198,  30,  85,\n",
              "         86, 155,  82, 156, 199,   2,   6, 200, 201,   2, 149,  30,   4,   5,\n",
              "          2, 202, 203,  33,  90,  17,  34, 194, 202, 192, 127,   2, 195,  22,\n",
              "         23, 204,   2, 149,  30, 136, 205, 206, 207,  73,  86, 136,  81, 146,\n",
              "         24,  25,   2, 149, 176,   2, 175,  78,   4, 208,  86, 135,  33,  23,\n",
              "         24, 163, 164, 109, 209,  17, 126, 165, 166, 167, 168, 211, 212, 214,\n",
              "         65,  86, 215,   2, 131, 216, 176,   2, 175,  33, 217,   5, 218,  78,\n",
              "         36, 219, 220,  30,  22,  65, 100,   2, 216, 213, 151,  19,   5, 221,\n",
              "         30, 184,  22,  23, 222,  19, 176, 223, 186,  78,  22,  45,  46, 146,\n",
              "         24, 100,  93,   2, 147, 131,  95, 142,   2, 192,  27, 223, 186,  24,\n",
              "        224, 191, 225, 200, 223, 190,  22,  45,  23,  24, 226,   2,  19, 188,\n",
              "         30, 132,   2,   6,   5, 227,  73,  22,  23, 131, 164,  28,  41,  12,\n",
              "        174,  34, 228,  27,  28,  38,  15,  22,  45,  46, 146,  24, 100,   2,\n",
              "        131,  95, 213, 229,   0,  30, 232, 183,   5,  81, 233,  33,  27,   2,\n",
              "        235,   6,   7,  30,  65,  86, 236, 237, 142,  63,  27,  17, 238, 200,\n",
              "          2,  89,  33,  45,  23,  24, 239,  17, 105, 240, 233, 142, 151, 152,\n",
              "         73,  94, 241,  45, 163,  22,   8,  17, 242, 176, 242, 238, 243,  89,\n",
              "         86, 141,   2,   3, 140,  78,  65,  86, 244, 245, 147, 246, 247,  33,\n",
              "         78, 248, 249, 147, 246, 238, 142,   2, 238, 243, 105, 240,  30, 136,\n",
              "        205, 206, 207,  73,  86, 136,  81, 146,  24,  25,   2, 149, 176,   2,\n",
              "        175,  78,   4, 208,  86, 135,  33,  23,  24, 163, 164, 109, 209,  17,\n",
              "        126, 165, 166, 167, 250,  73, 252, 253, 170, 212,   5,   2, 254,  24,\n",
              "         90,   2, 251,  33,  80, 116, 256,  50,  23,  24, 179,   2, 180,   7,\n",
              "         27,  28,  41,  23,  24, 257,  93,   2,   6, 258,  30, 136, 259, 140,\n",
              "         30, 123,  65,  86, 179, 149,  27,   2, 260,  35,  33,  45,  90,  17,\n",
              "        177,  24, 179,   7,  27, 260,  35, 142, 151, 152, 132,  22, 179,   8,\n",
              "          2, 261, 108,  30,  23, 219, 262, 252, 253,   5,  17,  75,  27,  76,\n",
              "          3,  30,   4, 263, 264, 252, 253,  33,   5,  24, 265, 262, 252, 253,\n",
              "        266,  81, 267, 252, 268,  30,  36,  44, 269, 268,  22, 270, 271, 174,\n",
              "          8, 262, 272,  97, 273, 274,  30,  36,  85,  22,  80, 275,  24, 141,\n",
              "         76,   6, 248,   8, 276,  78,  86, 136, 277,  22,  45,  46, 278,  30,\n",
              "         68,   5,   4, 263, 264, 252, 253, 280,  95, 282,  95, 158, 283, 284,\n",
              "        176, 286, 287, 288])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,X,y):\n",
        "    self.X = X;\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "quN4Oa_rsvqL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X,y)"
      ],
      "metadata": {
        "id": "ArUr5qXmteZ_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP3XhYRgth3l",
        "outputId": "7c55d3ad-1f16-4a99-e7b8-4526a6f5635c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
              " tensor(2))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "24LJMq71tjGK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMmodel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, X):\n",
        "    embedded = self.embedding(X)\n",
        "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "nv1IylxmtvsB"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMmodel(len(vocab))"
      ],
      "metadata": {
        "id": "iChgI135xmwp"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "KmHbnJOoxp9i"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMQix6a4x4X6",
        "outputId": "4e78ed80-a143-4e7c-de7e-3698b9da66bf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMmodel(\n",
              "  (embedding): Embedding(289, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=289, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "BYWaTJEmx5xD"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "JcI2tR0Px-rB"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "  for batch_x, batch_y in dataloader:\n",
        "    batch_x = batch_x.to(device)\n",
        "    batch_y = batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch_x)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {total_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MJfgxkZyJVX",
        "outputId": "6d555353-5e05-4d9f-e117-8d41c205e22e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 166.3473\n",
            "Epoch: 2, Loss: 145.8563\n",
            "Epoch: 3, Loss: 133.6804\n",
            "Epoch: 4, Loss: 121.7653\n",
            "Epoch: 5, Loss: 109.9800\n",
            "Epoch: 6, Loss: 98.3111\n",
            "Epoch: 7, Loss: 87.2056\n",
            "Epoch: 8, Loss: 77.0778\n",
            "Epoch: 9, Loss: 67.9413\n",
            "Epoch: 10, Loss: 60.2930\n",
            "Epoch: 11, Loss: 53.0254\n",
            "Epoch: 12, Loss: 46.4913\n",
            "Epoch: 13, Loss: 40.8347\n",
            "Epoch: 14, Loss: 35.8860\n",
            "Epoch: 15, Loss: 31.5798\n",
            "Epoch: 16, Loss: 27.8152\n",
            "Epoch: 17, Loss: 24.5102\n",
            "Epoch: 18, Loss: 21.5334\n",
            "Epoch: 19, Loss: 19.3592\n",
            "Epoch: 20, Loss: 17.2186\n",
            "Epoch: 21, Loss: 15.6636\n",
            "Epoch: 22, Loss: 14.1767\n",
            "Epoch: 23, Loss: 12.8368\n",
            "Epoch: 24, Loss: 11.7886\n",
            "Epoch: 25, Loss: 10.7297\n",
            "Epoch: 26, Loss: 10.0790\n",
            "Epoch: 27, Loss: 9.3696\n",
            "Epoch: 28, Loss: 9.0537\n",
            "Epoch: 29, Loss: 8.4786\n",
            "Epoch: 30, Loss: 7.9100\n",
            "Epoch: 31, Loss: 7.4583\n",
            "Epoch: 32, Loss: 7.1743\n",
            "Epoch: 33, Loss: 6.7634\n",
            "Epoch: 34, Loss: 6.4786\n",
            "Epoch: 35, Loss: 6.2534\n",
            "Epoch: 36, Loss: 6.1210\n",
            "Epoch: 37, Loss: 5.9497\n",
            "Epoch: 38, Loss: 5.7465\n",
            "Epoch: 39, Loss: 5.6498\n",
            "Epoch: 40, Loss: 5.2542\n",
            "Epoch: 41, Loss: 5.1467\n",
            "Epoch: 42, Loss: 5.0905\n",
            "Epoch: 43, Loss: 4.8990\n",
            "Epoch: 44, Loss: 5.0183\n",
            "Epoch: 45, Loss: 4.7797\n",
            "Epoch: 46, Loss: 4.7494\n",
            "Epoch: 47, Loss: 4.5275\n",
            "Epoch: 48, Loss: 4.4599\n",
            "Epoch: 49, Loss: 4.4865\n",
            "Epoch: 50, Loss: 4.3843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "def predict_next_word(model, vocab, text):\n",
        "  # tokenize\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "  # text -> numerical_indices\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "  # padding\n",
        "  padded_text = torch.tensor([0]*(61 - len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "\n",
        "  # send to model\n",
        "  output = model(padded_text)\n",
        "\n",
        "  # predicted index\n",
        "  val, idx = torch.max(output, dim=1)\n",
        "\n",
        "  # merge with text\n",
        "  return text + \" \" + list(vocab.keys())[idx]\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "_MoUlZLay1MG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_word(model, vocab, \"The course follows a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gbzPXW9T0wWm",
        "outputId": "a884ed63-90c5-43f1-9d95-242d264fe4c2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The course follows a monthly'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "num_tokens = 10\n",
        "input_text = \"The course follows a monthly\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "  output_text = predict_next_word(model, vocab, input_text)\n",
        "  print(output_text)\n",
        "  input_text = output_text\n",
        "  time.sleep(0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtGyloJo035L",
        "outputId": "b137938a-61d9-46c0-9185-811cb70e1997"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The course follows a monthly subscription\n",
            "The course follows a monthly subscription model\n",
            "The course follows a monthly subscription model where\n",
            "The course follows a monthly subscription model where you\n",
            "The course follows a monthly subscription model where you have\n",
            "The course follows a monthly subscription model where you have to\n",
            "The course follows a monthly subscription model where you have to make\n",
            "The course follows a monthly subscription model where you have to make monthly\n",
            "The course follows a monthly subscription model where you have to make monthly payments\n",
            "The course follows a monthly subscription model where you have to make monthly payments of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fzcxx_694CHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}